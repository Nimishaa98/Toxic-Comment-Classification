{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Toxic Comment Classification using BERT.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1p2ACunBLSy-8H_dYI1tEAx7LlBfHSj8t","authorship_tag":"ABX9TyMdk4rOcL5YhA5K4u2vYRfv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d0387b3f94c942a18a55c4a5bb151489":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_19f58cc8a1964684843762949b3aa578","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4a33f6806ae04956856bab2787c647ed","IPY_MODEL_2ab95e7c900e4a108abc552c855229c2"]}},"19f58cc8a1964684843762949b3aa578":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a33f6806ae04956856bab2787c647ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_92bff9e47ed54b31b915e64b218bead3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5b77ce39cdb34d49838d85a292968817"}},"2ab95e7c900e4a108abc552c855229c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_45c815c3f16c40d1996fee31223601d0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 1.78MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9983b4a056ea4120b3816d7ad868f1a9"}},"92bff9e47ed54b31b915e64b218bead3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5b77ce39cdb34d49838d85a292968817":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45c815c3f16c40d1996fee31223601d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9983b4a056ea4120b3816d7ad868f1a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"06a30e8471534189a997712c7128f632":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_95bafe4dadd94486923c0cce1fc5cf0b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_77d2b82154fc45e8ae018aa06c50ce79","IPY_MODEL_02bf9375b5164cf59798bfa2e869849f"]}},"95bafe4dadd94486923c0cce1fc5cf0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"77d2b82154fc45e8ae018aa06c50ce79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_50e017356dbb4b409ff694bf4b27439c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e7ee9a2dbcc43f6b3f76d2e19491d61"}},"02bf9375b5164cf59798bfa2e869849f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_91a8a91dba7c4f759c945c768c167832","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 44.2B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3a873c1c707d4e9cab31f823cf06ffe0"}},"50e017356dbb4b409ff694bf4b27439c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3e7ee9a2dbcc43f6b3f76d2e19491d61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91a8a91dba7c4f759c945c768c167832":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3a873c1c707d4e9cab31f823cf06ffe0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9742200498454a288c33b359018344e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3d33a92d47df47b9815bcaf1f0d40fef","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bf2c2bfe0cd841c4a4336aa9d4ca8c9c","IPY_MODEL_d95c77a3fac74d95a65b24276a4fc366"]}},"3d33a92d47df47b9815bcaf1f0d40fef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bf2c2bfe0cd841c4a4336aa9d4ca8c9c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_78096ac799564d3a9023e92fa4633a6a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05adab5875ab401689e7e2c33ff5c89a"}},"d95c77a3fac74d95a65b24276a4fc366":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e63ae1014f9b4b688f0aa5acc816d2c9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 2.74MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_57198661564a4c9caeb31190f2a6a0f6"}},"78096ac799564d3a9023e92fa4633a6a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"05adab5875ab401689e7e2c33ff5c89a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e63ae1014f9b4b688f0aa5acc816d2c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"57198661564a4c9caeb31190f2a6a0f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aHePIpOXF3hF","executionInfo":{"status":"ok","timestamp":1623396065306,"user_tz":-330,"elapsed":6722,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}},"outputId":"e0bdeaac-cf58-4de5-a481-e700370dde4b"},"source":["# Installing the transformers library\n","\n","!pip install -q transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 2.3MB 9.2MB/s \n","\u001b[K     |████████████████████████████████| 901kB 44.1MB/s \n","\u001b[K     |████████████████████████████████| 3.3MB 37.5MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U_-tZlSzGGx0","executionInfo":{"status":"ok","timestamp":1623396071752,"user_tz":-330,"elapsed":6451,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}}},"source":["# Importing ml libraries\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn import metrics\n","import transformers\n","import torch\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertTokenizer, BertModel, BertConfig\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"o22Da9cM8Uhp","executionInfo":{"status":"ok","timestamp":1623396071754,"user_tz":-330,"elapsed":29,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}}},"source":["# Setting up the device for GPU usage\n","\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"VZ1sfwuEGOaZ","executionInfo":{"status":"ok","timestamp":1623396074771,"user_tz":-330,"elapsed":3044,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}},"outputId":"23131592-3818-4d79-b3e7-211dd4dfce3d"},"source":["# Importing and preprocessing the data\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/Data Science Projects/Toxic Comment Classification/train.csv\")\n","df['list'] = df[df.columns[2:]].values.tolist()\n","new_df = df[['comment_text', 'list']].copy()\n","new_df.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text</th>\n","      <th>list</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Explanation\\nWhy the edits made under my usern...</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>D'aww! He matches this background colour I'm s...</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hey man, I'm really not trying to edit war. It...</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>You, sir, are my hero. Any chance you remember...</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        comment_text                list\n","0  Explanation\\nWhy the edits made under my usern...  [0, 0, 0, 0, 0, 0]\n","1  D'aww! He matches this background colour I'm s...  [0, 0, 0, 0, 0, 0]\n","2  Hey man, I'm really not trying to edit war. It...  [0, 0, 0, 0, 0, 0]\n","3  \"\\nMore\\nI can't make any real suggestions on ...  [0, 0, 0, 0, 0, 0]\n","4  You, sir, are my hero. Any chance you remember...  [0, 0, 0, 0, 0, 0]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165,"referenced_widgets":["d0387b3f94c942a18a55c4a5bb151489","19f58cc8a1964684843762949b3aa578","4a33f6806ae04956856bab2787c647ed","2ab95e7c900e4a108abc552c855229c2","92bff9e47ed54b31b915e64b218bead3","5b77ce39cdb34d49838d85a292968817","45c815c3f16c40d1996fee31223601d0","9983b4a056ea4120b3816d7ad868f1a9","06a30e8471534189a997712c7128f632","95bafe4dadd94486923c0cce1fc5cf0b","77d2b82154fc45e8ae018aa06c50ce79","02bf9375b5164cf59798bfa2e869849f","50e017356dbb4b409ff694bf4b27439c","3e7ee9a2dbcc43f6b3f76d2e19491d61","91a8a91dba7c4f759c945c768c167832","3a873c1c707d4e9cab31f823cf06ffe0","9742200498454a288c33b359018344e0","3d33a92d47df47b9815bcaf1f0d40fef","bf2c2bfe0cd841c4a4336aa9d4ca8c9c","d95c77a3fac74d95a65b24276a4fc366","78096ac799564d3a9023e92fa4633a6a","05adab5875ab401689e7e2c33ff5c89a","e63ae1014f9b4b688f0aa5acc816d2c9","57198661564a4c9caeb31190f2a6a0f6"]},"id":"z4-llBUZKWT4","executionInfo":{"status":"ok","timestamp":1623396077083,"user_tz":-330,"elapsed":2329,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}},"outputId":"6f95540c-5e34-4cb9-f855-e3bfe024f348"},"source":["# Defining some key variables and tokenizer that will be used later on in the training \n","MAX_LEN = 200\n","TRAIN_BATCH_SIZE = 8\n","VALID_BATCH_SIZE = 4\n","EPOCHS = 1\n","LEARNING_RATE = 1e-05\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0387b3f94c942a18a55c4a5bb151489","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06a30e8471534189a997712c7128f632","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9742200498454a288c33b359018344e0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P7j3OsLxqvqV","executionInfo":{"status":"ok","timestamp":1623396077085,"user_tz":-330,"elapsed":18,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}}},"source":["# This class is defined to accept the tokenizer, dataframe and max_length as input and generate tokenized output and tags\n","# that is used by the BERT model for training.\n","\n","\n","class CustomDataset(Dataset):\n","\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.comment_text = dataframe.comment_text\n","        self.targets = self.data.list\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.comment_text)\n","\n","    def __getitem__(self, index):\n","        comment_text = str(self.comment_text[index])\n","        comment_text = \" \".join(comment_text.split())   # These 2 lines are just to remove the special characters from the string such as \\n.\n","\n","        inputs = self.tokenizer.encode_plus(\n","            comment_text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding=True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n","        }"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bYkBLRaGsqZB","executionInfo":{"status":"ok","timestamp":1623396077088,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}},"outputId":"9be09b3c-7bfd-453f-e830-0f0524367287"},"source":["# Creating the dataset and dataloader for the neural network\n","\n","train_size = 0.8\n","train_dataset=new_df.sample(frac=train_size,random_state=200)\n","test_dataset=new_df.drop(train_dataset.index).reset_index(drop=True)\n","train_dataset = train_dataset.reset_index(drop=True)\n","\n","\n","print(\"FULL Dataset: {}\".format(new_df.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"TEST Dataset: {}\".format(test_dataset.shape))\n","\n","training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n","testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["FULL Dataset: (159571, 2)\n","TRAIN Dataset: (127657, 2)\n","TEST Dataset: (31914, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fTzJiMbg9fIy","executionInfo":{"status":"ok","timestamp":1623396334625,"user_tz":-330,"elapsed":391,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}},"outputId":"e5411805-e33b-4f82-cbac-5418184608aa"},"source":["training_set.__getitem__(0)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'ids': tensor([  101,  3125,  3195,  2005,  5978,  2023,  2071,  2022,  2661,  2125,\n","          1996,  2928,  2021,  2106, 13559,  2941,  3556,  1037,  3125,  2096,\n","          2652,  2005,  5978,  1029,  1045, 25664,  3246,  2023,  2001,  2053,\n","          7727,  2000,  1996,  6531,  2002,  3195,  2114,  2563,  2029,  1010,\n","          1997,  2607,  1010,  2001,  1999,  1037,  6531, 18297,  1012,  1996,\n","          3931,  2055,  1005,  3289, 27108,  2075,  9653,  2015,  1005,  2069,\n","          4447,  2002,  3195,  1037,  3125,  2005,  2028,  1997,  2010,  2252,\n","          3903,  1998,  1037,  4248,  4274,  3945,  2357,  2039,  2498,  1012,\n","           102]),\n"," 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1]),\n"," 'targets': tensor([0., 0., 0., 0., 0., 0.]),\n"," 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0])}"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"UIbnQezb1bAq","executionInfo":{"status":"ok","timestamp":1623396407443,"user_tz":-330,"elapsed":414,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}}},"source":["# Dataloader is used to for creating training and validation dataloader that load data to the neural network in a defined manner.\n","#  This is needed because all the data from the dataset cannot be loaded to the memory at once,\n","#  hence the amount of dataloaded to the memory and then passed to the neural network needs to be controlled.\n","# This control is achieved using the parameters such as batch_size and max_len.\n","\n","\n","train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **test_params)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQpOHgp16rOM","executionInfo":{"status":"ok","timestamp":1623348021483,"user_tz":-330,"elapsed":4902,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}},"outputId":"6c26745b-45d0-412a-eeb0-093ed884921b"},"source":["# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n","# The second argument for linear layer i.e. no. of dimensions is 6 since that is the total no. of categories \n","\n","class BERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n","        self.l2 = torch.nn.Dropout(0.3)\n","        self.l3 = torch.nn.Linear(768, 6)\n","    \n","    def forward(self, ids, mask, token_type_ids):\n","        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n","        output_2 = self.l2(output_1)\n","        output = self.l3(output_2)\n","        return output\n","\n","model = BERTClass()   # defining the model\n","model.to(device)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BERTClass(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l2): Dropout(p=0.3, inplace=False)\n","  (l3): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"NYqa8L9x8ChZ","executionInfo":{"status":"ok","timestamp":1623348021485,"user_tz":-330,"elapsed":50,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}}},"source":["# the loss function used will be a combination of Binary Cross Entropy which is implemented as BCELogits Loss in PyTorch\n","\n","def loss_fn(outputs, targets):\n","    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"HoLShVbP8n82","executionInfo":{"status":"ok","timestamp":1623348021486,"user_tz":-330,"elapsed":49,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}}},"source":["# Optimizer is used to update the weights of the neural network to improve its performance.\n","\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"lgJa10lj860L","executionInfo":{"status":"ok","timestamp":1623348021488,"user_tz":-330,"elapsed":49,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}}},"source":["# A training function is defined that trains the model on the training dataset.\n","\n","# The dataloader passes data to the model based on the batch size.\n","# Subsequent output from the model and the actual category are compared to calculate the loss.\n","# Loss value is used to optimize the weights of the neurons in the network.\n","# After every 5000 steps the loss value is printed in the console.\n","\n","def train(epoch):\n","    model.train()\n","    for _,data in enumerate(training_loader, 0):\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.float)\n","\n","        outputs = model(ids, mask, token_type_ids)\n","\n","        optimizer.zero_grad()\n","        loss = loss_fn(outputs, targets)\n","        if _%5000==0:\n","            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9Yeq2UT-N1O","executionInfo":{"status":"ok","timestamp":1623352901197,"user_tz":-330,"elapsed":4879757,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}},"outputId":"d5e8ffb6-1584-40bc-9466-475f571c6331"},"source":["for epoch in range(EPOCHS):\n","    train(epoch)\n","\n","# It can be seen that just after one epoch we are getting a minimal loss of 0.054."],"execution_count":13,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0, Loss:  0.6841009855270386\n","Epoch: 0, Loss:  0.007119165267795324\n","Epoch: 0, Loss:  0.006552674807608128\n","Epoch: 0, Loss:  0.05421310290694237\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ugcxFtBa-jEO","executionInfo":{"status":"ok","timestamp":1623352901207,"user_tz":-330,"elapsed":39,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}}},"source":["# Validating the model\n","\n","def validation(epoch):\n","    model.eval()\n","    fin_targets=[]\n","    fin_outputs=[]\n","    with torch.no_grad():\n","        for _, data in enumerate(testing_loader, 0):\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.float)\n","            outputs = model(ids, mask, token_type_ids)\n","            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n","            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n","    return fin_outputs, fin_targets"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zNLU0gv-f9A","executionInfo":{"status":"ok","timestamp":1623353347435,"user_tz":-330,"elapsed":446256,"user":{"displayName":"Nimisha Agrawal","photoUrl":"","userId":"04267917870265197370"}},"outputId":"14391980-9e9d-4721-f5f2-8801a5151c54"},"source":["# Following metrics are used to determine the model's performance\n","# 1. Accuracy\n","# 2. f1 Micro\n","# 3. f1 macro\n","\n","for epoch in range(EPOCHS):\n","    outputs, targets = validation(epoch)\n","    outputs = np.array(outputs) >= 0.5\n","    accuracy = metrics.accuracy_score(targets, outputs)\n","    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n","    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n","    print(f\"Accuracy Score = {accuracy}\")\n","    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n","    print(f\"F1 Score (Macro) = {f1_score_macro}\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy Score = 0.9279939838315473\n","F1 Score (Micro) = 0.7744687451527843\n","F1 Score (Macro) = 0.5672648167813132\n"],"name":"stdout"}]}]}